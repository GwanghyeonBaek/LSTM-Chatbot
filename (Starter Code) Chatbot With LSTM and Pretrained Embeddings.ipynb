{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJAWnBFlkE2w"
   },
   "source": [
    "# LSTM Bot\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this project, you will build a chatbot that can converse with you at the command line. The chatbot will use a Sequence to Sequence text generation architecture with an LSTM as it's memory unit. You will also learn to use pretrained word embeddings to improve the performance of the model. At the conclusion of the project, you will be able to show your chatbot to potential employers.\n",
    "\n",
    "Additionally, you have the option to use pretrained word embeddings in your model. We have loaded Brown Embeddings from Gensim in the starter code below. You can compare the performance of your model with pre-trained embeddings against a model without the embeddings.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "A sequence to sequence model (Seq2Seq) has two components:\n",
    "- An Encoder consisting of an embedding layer and LSTM unit.\n",
    "- A Decoder consisting of an embedding layer, LSTM unit, and linear output unit.\n",
    "\n",
    "The Seq2Seq model works by accepting an input into the Encoder, passing the hidden state from the Encoder to the Decoder, which the Decoder uses to output a series of token predictions.\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "- Pytorch\n",
    "- Numpy\n",
    "- Pandas\n",
    "- NLTK\n",
    "- Gzip\n",
    "- Gensim\n",
    "\n",
    "\n",
    "Please choose a dataset from the Torchtext website. We recommend looking at the Squad dataset first. Here is a link to the website where you can view your options:\n",
    "\n",
    "- https://pytorch.org/text/stable/datasets.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch==1.12.0 in /root/.local/lib/python3.7/site-packages (1.12.0)\n",
      "Requirement already satisfied: torchdata==0.4.0 in /root/.local/lib/python3.7/site-packages (0.4.0)\n",
      "Requirement already satisfied: torchtext==0.13.0 in /root/.local/lib/python3.7/site-packages (0.13.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.12.0) (3.7.4.1)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.7/site-packages (from torchdata==0.4.0) (1.25.7)\n",
      "Requirement already satisfied: portalocker>=2.0.0 in /root/.local/lib/python3.7/site-packages (from torchdata==0.4.0) (2.7.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchdata==0.4.0) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtext==0.13.0) (4.43.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchtext==0.13.0) (1.21.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->torchdata==0.4.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchdata==0.4.0) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchdata==0.4.0) (2019.11.28)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.12.0 torchdata==0.4.0 torchtext==0.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.Data import loadDF, prepare_text, getPairs, toTensor, getMaxLen\n",
    "from util.Models import Seq2Seq\n",
    "from util.Vocab import Vocab\n",
    "from util.Train import train\n",
    "from util.Evaluate import evaluate\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "hidden_size = 256 # encoder and decoder hidden size\n",
    "batch_size = 256\n",
    "epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import torch\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = loadDF('data')\n",
    "data_df = data_df.iloc[:5000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? \n",
      "<  Saint Bernadette Soubirous \n",
      "\n",
      ">  What is in front of the Notre Dame Main Building? \n",
      "<  a copper statue of Christ \n",
      "\n",
      ">  The Basilica of the Sacred heart at Notre Dame is beside to which structure? \n",
      "<  the Main Building \n",
      "\n",
      ">  What is the Grotto at Notre Dame? \n",
      "<  a Marian place of prayer and reflection \n",
      "\n",
      ">  What sits on top of the Main Building at Notre Dame? \n",
      "<  a golden statue of the Virgin Mary \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5):\n",
    "    print(\"> \", data_df.iloc[i,0], \"\\n< \", data_df.iloc[i,1], \"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['Question'] = data_df['Question'].apply(prepare_text)\n",
    "data_df['Answer'] = data_df['Answer'].apply(prepare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = getPairs(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 29)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_src, max_trg = getMaxLen(pairs)\n",
    "max_trg, max_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_vocab = Vocab()\n",
    "A_vocab = Vocab()\n",
    "\n",
    "for pair in pairs:\n",
    "    Q_vocab.add_words(pair[0])\n",
    "    A_vocab.add_words(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = [toTensor(Q_vocab, pair[0]) for pair in pairs]\n",
    "target_data = [toTensor(A_vocab, pair[1]) for pair in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eg81uNTWixbi",
    "outputId": "9c0f9eda-75fb-4526-e9b6-f9a76eeeb007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Improved\n",
      "best loss changed : 100 ---> 5.642314862336766\n",
      "1/150 Epoch  -  Training Loss = 6.4542  -  Validation Loss = 5.6423\n",
      "Model Improved\n",
      "best loss changed : 5.642314862336766 ---> 5.43468880971718\n",
      "2/150 Epoch  -  Training Loss = 5.4901  -  Validation Loss = 5.4347\n",
      "Model Improved\n",
      "best loss changed : 5.43468880971718 ---> 5.304959308488919\n",
      "3/150 Epoch  -  Training Loss = 5.3046  -  Validation Loss = 5.3050\n",
      "Model Improved\n",
      "best loss changed : 5.304959308488919 ---> 5.239271837211345\n",
      "4/150 Epoch  -  Training Loss = 5.2206  -  Validation Loss = 5.2393\n",
      "Model Improved\n",
      "best loss changed : 5.239271837211345 ---> 5.17715295189235\n",
      "5/150 Epoch  -  Training Loss = 5.1561  -  Validation Loss = 5.1772\n",
      "Model Improved\n",
      "best loss changed : 5.17715295189235 ---> 5.1107371987414965\n",
      "6/150 Epoch  -  Training Loss = 5.0921  -  Validation Loss = 5.1107\n",
      "Model Improved\n",
      "best loss changed : 5.1107371987414965 ---> 4.9842802104718436\n",
      "7/150 Epoch  -  Training Loss = 5.0019  -  Validation Loss = 4.9843\n",
      "Model Improved\n",
      "best loss changed : 4.9842802104718436 ---> 4.857411009323697\n",
      "8/150 Epoch  -  Training Loss = 4.8912  -  Validation Loss = 4.8574\n",
      "Model Improved\n",
      "best loss changed : 4.857411009323697 ---> 4.716003043667165\n",
      "9/150 Epoch  -  Training Loss = 4.7582  -  Validation Loss = 4.7160\n",
      "Model Improved\n",
      "best loss changed : 4.716003043667165 ---> 4.655036801294564\n",
      "10/150 Epoch  -  Training Loss = 4.6513  -  Validation Loss = 4.6550\n",
      "Model Improved\n",
      "best loss changed : 4.655036801294564 ---> 4.480646101077175\n",
      "11/150 Epoch  -  Training Loss = 4.4784  -  Validation Loss = 4.4806\n",
      "Model Improved\n",
      "best loss changed : 4.480646101077175 ---> 4.299172636941701\n",
      "12/150 Epoch  -  Training Loss = 4.3247  -  Validation Loss = 4.2992\n",
      "Model Improved\n",
      "best loss changed : 4.299172636941701 ---> 4.1023194666781455\n",
      "13/150 Epoch  -  Training Loss = 4.1339  -  Validation Loss = 4.1023\n",
      "Model Improved\n",
      "best loss changed : 4.1023194666781455 ---> 3.914609017358775\n",
      "14/150 Epoch  -  Training Loss = 3.9131  -  Validation Loss = 3.9146\n",
      "Model Improved\n",
      "best loss changed : 3.914609017358775 ---> 3.758924179094958\n",
      "15/150 Epoch  -  Training Loss = 3.7090  -  Validation Loss = 3.7589\n",
      "Model Improved\n",
      "best loss changed : 3.758924179094958 ---> 3.6505614440759477\n",
      "16/150 Epoch  -  Training Loss = 3.5235  -  Validation Loss = 3.6506\n",
      "Model Improved\n",
      "best loss changed : 3.6505614440759477 ---> 3.4500587902037925\n",
      "17/150 Epoch  -  Training Loss = 3.3269  -  Validation Loss = 3.4501\n",
      "Model Improved\n",
      "best loss changed : 3.4500587902037925 ---> 3.2476255524726145\n",
      "18/150 Epoch  -  Training Loss = 3.1573  -  Validation Loss = 3.2476\n",
      "Model Improved\n",
      "best loss changed : 3.2476255524726145 ---> 3.1870375538963125\n",
      "19/150 Epoch  -  Training Loss = 2.9623  -  Validation Loss = 3.1870\n",
      "Model Improved\n",
      "best loss changed : 3.1870375538963125 ---> 2.96112038068522\n",
      "20/150 Epoch  -  Training Loss = 2.7339  -  Validation Loss = 2.9611\n",
      "Model Improved\n",
      "best loss changed : 2.96112038068522 ---> 2.664121833385206\n",
      "21/150 Epoch  -  Training Loss = 2.5151  -  Validation Loss = 2.6641\n",
      "Model Improved\n",
      "best loss changed : 2.664121833385206 ---> 2.500739256401801\n",
      "22/150 Epoch  -  Training Loss = 2.2750  -  Validation Loss = 2.5007\n",
      "Model Improved\n",
      "best loss changed : 2.500739256401801 ---> 2.297633145553391\n",
      "23/150 Epoch  -  Training Loss = 2.0381  -  Validation Loss = 2.2976\n",
      "Model Improved\n",
      "best loss changed : 2.297633145553391 ---> 2.065350028079431\n",
      "24/150 Epoch  -  Training Loss = 1.8608  -  Validation Loss = 2.0654\n",
      "Model Improved\n",
      "best loss changed : 2.065350028079431 ---> 1.9795339036165942\n",
      "25/150 Epoch  -  Training Loss = 1.7118  -  Validation Loss = 1.9795\n",
      "Model Improved\n",
      "best loss changed : 1.9795339036165942 ---> 1.9501555774113934\n",
      "26/150 Epoch  -  Training Loss = 1.5443  -  Validation Loss = 1.9502\n",
      "Model Improved\n",
      "best loss changed : 1.9501555774113934 ---> 1.7576886121743642\n",
      "27/150 Epoch  -  Training Loss = 1.4199  -  Validation Loss = 1.7577\n",
      "Model Improved\n",
      "best loss changed : 1.7576886121743642 ---> 1.5849353458422795\n",
      "28/150 Epoch  -  Training Loss = 1.2875  -  Validation Loss = 1.5849\n",
      "Model Improved\n",
      "best loss changed : 1.5849353458422795 ---> 1.4479725785532584\n",
      "29/150 Epoch  -  Training Loss = 1.1499  -  Validation Loss = 1.4480\n",
      "Model Improved\n",
      "best loss changed : 1.4479725785532584 ---> 1.3939684627506357\n",
      "30/150 Epoch  -  Training Loss = 1.0380  -  Validation Loss = 1.3940\n",
      "Model Improved\n",
      "best loss changed : 1.3939684627506357 ---> 1.2185995708284927\n",
      "31/150 Epoch  -  Training Loss = 0.9340  -  Validation Loss = 1.2186\n",
      "Model Improved\n",
      "best loss changed : 1.2185995708284927 ---> 1.184809650612924\n",
      "32/150 Epoch  -  Training Loss = 0.8491  -  Validation Loss = 1.1848\n",
      "Model Improved\n",
      "best loss changed : 1.184809650612924 ---> 1.1056434231548529\n",
      "33/150 Epoch  -  Training Loss = 0.7736  -  Validation Loss = 1.1056\n",
      "Model Improved\n",
      "best loss changed : 1.1056434231548529 ---> 1.033108996867744\n",
      "34/150 Epoch  -  Training Loss = 0.6984  -  Validation Loss = 1.0331\n",
      "Model Improved\n",
      "best loss changed : 1.033108996867744 ---> 0.8378124971934059\n",
      "35/150 Epoch  -  Training Loss = 0.5934  -  Validation Loss = 0.8378\n",
      "Model Improved\n",
      "best loss changed : 0.8378124971934059 ---> 0.8162192473495873\n",
      "36/150 Epoch  -  Training Loss = 0.5389  -  Validation Loss = 0.8162\n",
      "Model Improved\n",
      "best loss changed : 0.8162192473495873 ---> 0.6941727674349681\n",
      "37/150 Epoch  -  Training Loss = 0.4774  -  Validation Loss = 0.6942\n",
      "Model Improved\n",
      "best loss changed : 0.6941727674349681 ---> 0.6546692770590133\n",
      "38/150 Epoch  -  Training Loss = 0.4265  -  Validation Loss = 0.6547\n",
      "Model Improved\n",
      "best loss changed : 0.6546692770590133 ---> 0.5528631910664333\n",
      "39/150 Epoch  -  Training Loss = 0.3811  -  Validation Loss = 0.5529\n",
      "Model Improved\n",
      "best loss changed : 0.5528631910664333 ---> 0.5415068070660757\n",
      "40/150 Epoch  -  Training Loss = 0.3474  -  Validation Loss = 0.5415\n",
      "Model Improved\n",
      "best loss changed : 0.5415068070660757 ---> 0.43853922049983657\n",
      "41/150 Epoch  -  Training Loss = 0.3185  -  Validation Loss = 0.4385\n",
      "early stop counter : 1/10\n",
      "best loss : 0.43853922049983657\n",
      "42/150 Epoch  -  Training Loss = 0.2868  -  Validation Loss = 0.4457\n",
      "Model Improved\n",
      "best loss changed : 0.43853922049983657 ---> 0.38526139987526536\n",
      "43/150 Epoch  -  Training Loss = 0.2668  -  Validation Loss = 0.3853\n",
      "early stop counter : 1/10\n",
      "best loss : 0.38526139987526536\n",
      "44/150 Epoch  -  Training Loss = 0.2462  -  Validation Loss = 0.4085\n",
      "Model Improved\n",
      "best loss changed : 0.38526139987526536 ---> 0.3375006142920222\n",
      "45/150 Epoch  -  Training Loss = 0.2352  -  Validation Loss = 0.3375\n",
      "Model Improved\n",
      "best loss changed : 0.3375006142920222 ---> 0.31681762325719176\n",
      "46/150 Epoch  -  Training Loss = 0.2118  -  Validation Loss = 0.3168\n",
      "early stop counter : 1/10\n",
      "best loss : 0.31681762325719176\n",
      "47/150 Epoch  -  Training Loss = 0.2032  -  Validation Loss = 0.3230\n",
      "Model Improved\n",
      "best loss changed : 0.31681762325719176 ---> 0.260230291628537\n",
      "48/150 Epoch  -  Training Loss = 0.1868  -  Validation Loss = 0.2602\n",
      "early stop counter : 1/10\n",
      "best loss : 0.260230291628537\n",
      "49/150 Epoch  -  Training Loss = 0.1738  -  Validation Loss = 0.2686\n",
      "Model Improved\n",
      "best loss changed : 0.260230291628537 ---> 0.22008623233591976\n",
      "50/150 Epoch  -  Training Loss = 0.1609  -  Validation Loss = 0.2201\n",
      "Model Improved\n",
      "best loss changed : 0.22008623233591976 ---> 0.20372582884785814\n",
      "51/150 Epoch  -  Training Loss = 0.1480  -  Validation Loss = 0.2037\n",
      "Model Improved\n",
      "best loss changed : 0.20372582884785814 ---> 0.19518168091168336\n",
      "52/150 Epoch  -  Training Loss = 0.1378  -  Validation Loss = 0.1952\n",
      "Model Improved\n",
      "best loss changed : 0.19518168091168336 ---> 0.15824093478245768\n",
      "53/150 Epoch  -  Training Loss = 0.1252  -  Validation Loss = 0.1582\n",
      "Model Improved\n",
      "best loss changed : 0.15824093478245768 ---> 0.14628723909188743\n",
      "54/150 Epoch  -  Training Loss = 0.1136  -  Validation Loss = 0.1463\n",
      "Model Improved\n",
      "best loss changed : 0.14628723909188743 ---> 0.1372514481258011\n",
      "55/150 Epoch  -  Training Loss = 0.1071  -  Validation Loss = 0.1373\n",
      "Model Improved\n",
      "best loss changed : 0.1372514481258011 ---> 0.12093652026273559\n",
      "56/150 Epoch  -  Training Loss = 0.0992  -  Validation Loss = 0.1209\n",
      "Model Improved\n",
      "best loss changed : 0.12093652026273559 ---> 0.11860476647355396\n",
      "57/150 Epoch  -  Training Loss = 0.0933  -  Validation Loss = 0.1186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Improved\n",
      "best loss changed : 0.11860476647355396 ---> 0.10722762205731616\n",
      "58/150 Epoch  -  Training Loss = 0.0889  -  Validation Loss = 0.1072\n",
      "Model Improved\n",
      "best loss changed : 0.10722762205731616 ---> 0.10191054622812475\n",
      "59/150 Epoch  -  Training Loss = 0.0839  -  Validation Loss = 0.1019\n",
      "Model Improved\n",
      "best loss changed : 0.10191054622812475 ---> 0.09408089323986203\n",
      "60/150 Epoch  -  Training Loss = 0.0798  -  Validation Loss = 0.0941\n",
      "Model Improved\n",
      "best loss changed : 0.09408089323986203 ---> 0.08772642673981008\n",
      "61/150 Epoch  -  Training Loss = 0.0753  -  Validation Loss = 0.0877\n",
      "Model Improved\n",
      "best loss changed : 0.08772642673981008 ---> 0.08723713334250215\n",
      "62/150 Epoch  -  Training Loss = 0.0716  -  Validation Loss = 0.0872\n",
      "Model Improved\n",
      "best loss changed : 0.08723713334250215 ---> 0.07792061133235836\n",
      "63/150 Epoch  -  Training Loss = 0.0687  -  Validation Loss = 0.0779\n",
      "Model Improved\n",
      "best loss changed : 0.07792061133235836 ---> 0.0721203631962891\n",
      "64/150 Epoch  -  Training Loss = 0.0634  -  Validation Loss = 0.0721\n",
      "Model Improved\n",
      "best loss changed : 0.0721203631962891 ---> 0.0709541869576001\n",
      "65/150 Epoch  -  Training Loss = 0.0610  -  Validation Loss = 0.0710\n",
      "Model Improved\n",
      "best loss changed : 0.0709541869576001 ---> 0.063487051211982\n",
      "66/150 Epoch  -  Training Loss = 0.0578  -  Validation Loss = 0.0635\n",
      "Model Improved\n",
      "best loss changed : 0.063487051211982 ---> 0.06099664243740021\n",
      "67/150 Epoch  -  Training Loss = 0.0534  -  Validation Loss = 0.0610\n",
      "Model Improved\n",
      "best loss changed : 0.06099664243740021 ---> 0.0583365394844494\n",
      "68/150 Epoch  -  Training Loss = 0.0511  -  Validation Loss = 0.0583\n",
      "Model Improved\n",
      "best loss changed : 0.0583365394844494 ---> 0.0536434516979058\n",
      "69/150 Epoch  -  Training Loss = 0.0480  -  Validation Loss = 0.0536\n",
      "Model Improved\n",
      "best loss changed : 0.0536434516979058 ---> 0.05119819463163027\n",
      "70/150 Epoch  -  Training Loss = 0.0462  -  Validation Loss = 0.0512\n",
      "Model Improved\n",
      "best loss changed : 0.05119819463163027 ---> 0.05004956049431598\n",
      "71/150 Epoch  -  Training Loss = 0.0434  -  Validation Loss = 0.0500\n",
      "Model Improved\n",
      "best loss changed : 0.05004956049431598 ---> 0.04625960573260173\n",
      "72/150 Epoch  -  Training Loss = 0.0415  -  Validation Loss = 0.0463\n",
      "Model Improved\n",
      "best loss changed : 0.04625960573260173 ---> 0.04465383644036129\n",
      "73/150 Epoch  -  Training Loss = 0.0399  -  Validation Loss = 0.0447\n",
      "Model Improved\n",
      "best loss changed : 0.04465383644036129 ---> 0.04339773882361431\n",
      "74/150 Epoch  -  Training Loss = 0.0390  -  Validation Loss = 0.0434\n",
      "Model Improved\n",
      "best loss changed : 0.04339773882361431 ---> 0.04089965204555523\n",
      "75/150 Epoch  -  Training Loss = 0.0371  -  Validation Loss = 0.0409\n",
      "Model Improved\n",
      "best loss changed : 0.04089965204555523 ---> 0.04008837606652159\n",
      "76/150 Epoch  -  Training Loss = 0.0356  -  Validation Loss = 0.0401\n",
      "Model Improved\n",
      "best loss changed : 0.04008837606652159 ---> 0.03836372590741611\n",
      "77/150 Epoch  -  Training Loss = 0.0342  -  Validation Loss = 0.0384\n",
      "Model Improved\n",
      "best loss changed : 0.03836372590741611 ---> 0.035725468701668206\n",
      "78/150 Epoch  -  Training Loss = 0.0327  -  Validation Loss = 0.0357\n",
      "Model Improved\n",
      "best loss changed : 0.035725468701668206 ---> 0.034336915812685824\n",
      "79/150 Epoch  -  Training Loss = 0.0310  -  Validation Loss = 0.0343\n",
      "Model Improved\n",
      "best loss changed : 0.034336915812685824 ---> 0.03338980587470799\n",
      "80/150 Epoch  -  Training Loss = 0.0300  -  Validation Loss = 0.0334\n",
      "Model Improved\n",
      "best loss changed : 0.03338980587470799 ---> 0.03158982118301384\n",
      "81/150 Epoch  -  Training Loss = 0.0287  -  Validation Loss = 0.0316\n",
      "Model Improved\n",
      "best loss changed : 0.03158982118301384 ---> 0.030350909368352302\n",
      "82/150 Epoch  -  Training Loss = 0.0275  -  Validation Loss = 0.0304\n",
      "Model Improved\n",
      "best loss changed : 0.030350909368352302 ---> 0.029933272524028588\n",
      "83/150 Epoch  -  Training Loss = 0.0264  -  Validation Loss = 0.0299\n",
      "Model Improved\n",
      "best loss changed : 0.029933272524028588 ---> 0.028428485491386952\n",
      "84/150 Epoch  -  Training Loss = 0.0257  -  Validation Loss = 0.0284\n",
      "Model Improved\n",
      "best loss changed : 0.028428485491386952 ---> 0.027235057909613246\n",
      "85/150 Epoch  -  Training Loss = 0.0248  -  Validation Loss = 0.0272\n",
      "Model Improved\n",
      "best loss changed : 0.027235057909613246 ---> 0.02645759267245113\n",
      "86/150 Epoch  -  Training Loss = 0.0239  -  Validation Loss = 0.0265\n",
      "Model Improved\n",
      "best loss changed : 0.02645759267245113 ---> 0.0253357504377121\n",
      "87/150 Epoch  -  Training Loss = 0.0231  -  Validation Loss = 0.0253\n",
      "Model Improved\n",
      "best loss changed : 0.0253357504377121 ---> 0.024423746915266255\n",
      "88/150 Epoch  -  Training Loss = 0.0223  -  Validation Loss = 0.0244\n",
      "Model Improved\n",
      "best loss changed : 0.024423746915266255 ---> 0.02369511100598407\n",
      "89/150 Epoch  -  Training Loss = 0.0214  -  Validation Loss = 0.0237\n",
      "Model Improved\n",
      "best loss changed : 0.02369511100598407 ---> 0.022833895821710255\n",
      "90/150 Epoch  -  Training Loss = 0.0209  -  Validation Loss = 0.0228\n",
      "Model Improved\n",
      "best loss changed : 0.022833895821710255 ---> 0.02207212572050079\n",
      "91/150 Epoch  -  Training Loss = 0.0202  -  Validation Loss = 0.0221\n",
      "Model Improved\n",
      "best loss changed : 0.02207212572050079 ---> 0.021660823506778424\n",
      "92/150 Epoch  -  Training Loss = 0.0196  -  Validation Loss = 0.0217\n",
      "Model Improved\n",
      "best loss changed : 0.021660823506778424 ---> 0.021098443131513996\n",
      "93/150 Epoch  -  Training Loss = 0.0190  -  Validation Loss = 0.0211\n",
      "Model Improved\n",
      "best loss changed : 0.021098443131513996 ---> 0.0203398185937131\n",
      "94/150 Epoch  -  Training Loss = 0.0186  -  Validation Loss = 0.0203\n",
      "Model Improved\n",
      "best loss changed : 0.0203398185937131 ---> 0.020126096820597638\n",
      "95/150 Epoch  -  Training Loss = 0.0180  -  Validation Loss = 0.0201\n",
      "Model Improved\n",
      "best loss changed : 0.020126096820597638 ---> 0.01917597001495522\n",
      "96/150 Epoch  -  Training Loss = 0.0174  -  Validation Loss = 0.0192\n",
      "Model Improved\n",
      "best loss changed : 0.01917597001495522 ---> 0.01873407290559468\n",
      "97/150 Epoch  -  Training Loss = 0.0171  -  Validation Loss = 0.0187\n",
      "Model Improved\n",
      "best loss changed : 0.01873407290559468 ---> 0.018448257593087717\n",
      "98/150 Epoch  -  Training Loss = 0.0165  -  Validation Loss = 0.0184\n",
      "Model Improved\n",
      "best loss changed : 0.018448257593087717 ---> 0.01791557459460375\n",
      "99/150 Epoch  -  Training Loss = 0.0161  -  Validation Loss = 0.0179\n",
      "Model Improved\n",
      "best loss changed : 0.01791557459460375 ---> 0.017128486764075673\n",
      "100/150 Epoch  -  Training Loss = 0.0156  -  Validation Loss = 0.0171\n",
      "Model Improved\n",
      "best loss changed : 0.017128486764075673 ---> 0.016691664924702646\n",
      "101/150 Epoch  -  Training Loss = 0.0152  -  Validation Loss = 0.0167\n",
      "Model Improved\n",
      "best loss changed : 0.016691664924702646 ---> 0.01625913784278359\n",
      "102/150 Epoch  -  Training Loss = 0.0148  -  Validation Loss = 0.0163\n",
      "Model Improved\n",
      "best loss changed : 0.01625913784278359 ---> 0.015803559226606142\n",
      "103/150 Epoch  -  Training Loss = 0.0145  -  Validation Loss = 0.0158\n",
      "Model Improved\n",
      "best loss changed : 0.015803559226606142 ---> 0.01532657923512412\n",
      "104/150 Epoch  -  Training Loss = 0.0140  -  Validation Loss = 0.0153\n",
      "Model Improved\n",
      "best loss changed : 0.01532657923512412 ---> 0.01495610894807787\n",
      "105/150 Epoch  -  Training Loss = 0.0137  -  Validation Loss = 0.0150\n",
      "Model Improved\n",
      "best loss changed : 0.01495610894807787 ---> 0.014599052567470384\n",
      "106/150 Epoch  -  Training Loss = 0.0133  -  Validation Loss = 0.0146\n",
      "Model Improved\n",
      "best loss changed : 0.014599052567470384 ---> 0.014182506957167097\n",
      "107/150 Epoch  -  Training Loss = 0.0132  -  Validation Loss = 0.0142\n",
      "Model Improved\n",
      "best loss changed : 0.014182506957167097 ---> 0.013885331599103639\n",
      "108/150 Epoch  -  Training Loss = 0.0129  -  Validation Loss = 0.0139\n",
      "Model Improved\n",
      "best loss changed : 0.013885331599103639 ---> 0.013600733362701815\n",
      "109/150 Epoch  -  Training Loss = 0.0126  -  Validation Loss = 0.0136\n",
      "Model Improved\n",
      "best loss changed : 0.013600733362701815 ---> 0.01333048873815727\n",
      "110/150 Epoch  -  Training Loss = 0.0124  -  Validation Loss = 0.0133\n",
      "Model Improved\n",
      "best loss changed : 0.01333048873815727 ---> 0.012983900160645637\n",
      "111/150 Epoch  -  Training Loss = 0.0124  -  Validation Loss = 0.0130\n",
      "Model Improved\n",
      "best loss changed : 0.012983900160645637 ---> 0.012699424852216156\n",
      "112/150 Epoch  -  Training Loss = 0.0120  -  Validation Loss = 0.0127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Improved\n",
      "best loss changed : 0.012699424852216156 ---> 0.012421036150912114\n",
      "113/150 Epoch  -  Training Loss = 0.0117  -  Validation Loss = 0.0124\n",
      "Model Improved\n",
      "best loss changed : 0.012421036150912114 ---> 0.01197068461272086\n",
      "114/150 Epoch  -  Training Loss = 0.0116  -  Validation Loss = 0.0120\n",
      "Model Improved\n",
      "best loss changed : 0.01197068461272086 ---> 0.011621422797935141\n",
      "115/150 Epoch  -  Training Loss = 0.0113  -  Validation Loss = 0.0116\n",
      "Model Improved\n",
      "best loss changed : 0.011621422797935141 ---> 0.01137540420040689\n",
      "116/150 Epoch  -  Training Loss = 0.0109  -  Validation Loss = 0.0114\n",
      "Model Improved\n",
      "best loss changed : 0.01137540420040689 ---> 0.011087986929503416\n",
      "117/150 Epoch  -  Training Loss = 0.0106  -  Validation Loss = 0.0111\n",
      "Model Improved\n",
      "best loss changed : 0.011087986929503416 ---> 0.010939851468617116\n",
      "118/150 Epoch  -  Training Loss = 0.0104  -  Validation Loss = 0.0109\n",
      "Model Improved\n",
      "best loss changed : 0.010939851468617116 ---> 0.010692847618867228\n",
      "119/150 Epoch  -  Training Loss = 0.0102  -  Validation Loss = 0.0107\n",
      "Model Improved\n",
      "best loss changed : 0.010692847618867228 ---> 0.010465896618429315\n",
      "120/150 Epoch  -  Training Loss = 0.0101  -  Validation Loss = 0.0105\n",
      "Model Improved\n",
      "best loss changed : 0.010465896618429315 ---> 0.010301556455767916\n",
      "121/150 Epoch  -  Training Loss = 0.0100  -  Validation Loss = 0.0103\n",
      "Model Improved\n",
      "best loss changed : 0.010301556455767916 ---> 0.009972800922473895\n",
      "122/150 Epoch  -  Training Loss = 0.0097  -  Validation Loss = 0.0100\n",
      "Model Improved\n",
      "best loss changed : 0.009972800922473895 ---> 0.00979123191855142\n",
      "123/150 Epoch  -  Training Loss = 0.0097  -  Validation Loss = 0.0098\n",
      "Model Improved\n",
      "best loss changed : 0.00979123191855142 ---> 0.009533668079307306\n",
      "124/150 Epoch  -  Training Loss = 0.0094  -  Validation Loss = 0.0095\n",
      "Model Improved\n",
      "best loss changed : 0.009533668079307306 ---> 0.009360776361801038\n",
      "125/150 Epoch  -  Training Loss = 0.0093  -  Validation Loss = 0.0094\n",
      "Model Improved\n",
      "best loss changed : 0.009360776361801038 ---> 0.009175233084604523\n",
      "126/150 Epoch  -  Training Loss = 0.0090  -  Validation Loss = 0.0092\n",
      "Model Improved\n",
      "best loss changed : 0.009175233084604523 ---> 0.009001803192963618\n",
      "127/150 Epoch  -  Training Loss = 0.0090  -  Validation Loss = 0.0090\n",
      "Model Improved\n",
      "best loss changed : 0.009001803192963618 ---> 0.008817992756678978\n",
      "128/150 Epoch  -  Training Loss = 0.0087  -  Validation Loss = 0.0088\n",
      "Model Improved\n",
      "best loss changed : 0.008817992756678978 ---> 0.008647405172300853\n",
      "129/150 Epoch  -  Training Loss = 0.0086  -  Validation Loss = 0.0086\n",
      "Model Improved\n",
      "best loss changed : 0.008647405172300853 ---> 0.00848555546988585\n",
      "130/150 Epoch  -  Training Loss = 0.0086  -  Validation Loss = 0.0085\n",
      "Model Improved\n",
      "best loss changed : 0.00848555546988585 ---> 0.008311441587306605\n",
      "131/150 Epoch  -  Training Loss = 0.0084  -  Validation Loss = 0.0083\n",
      "Model Improved\n",
      "best loss changed : 0.008311441587306605 ---> 0.008152562584624969\n",
      "132/150 Epoch  -  Training Loss = 0.0082  -  Validation Loss = 0.0082\n",
      "Model Improved\n",
      "best loss changed : 0.008152562584624969 ---> 0.007980030832589104\n",
      "133/150 Epoch  -  Training Loss = 0.0081  -  Validation Loss = 0.0080\n",
      "Model Improved\n",
      "best loss changed : 0.007980030832589104 ---> 0.007864482274181342\n",
      "134/150 Epoch  -  Training Loss = 0.0079  -  Validation Loss = 0.0079\n",
      "Model Improved\n",
      "best loss changed : 0.007864482274181342 ---> 0.007740785622713481\n",
      "135/150 Epoch  -  Training Loss = 0.0079  -  Validation Loss = 0.0077\n",
      "Model Improved\n",
      "best loss changed : 0.007740785622713481 ---> 0.007540709292784892\n",
      "136/150 Epoch  -  Training Loss = 0.0076  -  Validation Loss = 0.0075\n",
      "Model Improved\n",
      "best loss changed : 0.007540709292784892 ---> 0.007383998759434044\n",
      "137/150 Epoch  -  Training Loss = 0.0077  -  Validation Loss = 0.0074\n",
      "Model Improved\n",
      "best loss changed : 0.007383998759434044 ---> 0.007345170674831243\n",
      "138/150 Epoch  -  Training Loss = 0.0075  -  Validation Loss = 0.0073\n",
      "Model Improved\n",
      "best loss changed : 0.007345170674831243 ---> 0.007182382657934034\n",
      "139/150 Epoch  -  Training Loss = 0.0073  -  Validation Loss = 0.0072\n",
      "Model Improved\n",
      "best loss changed : 0.007182382657934034 ---> 0.007015397362348308\n",
      "140/150 Epoch  -  Training Loss = 0.0073  -  Validation Loss = 0.0070\n",
      "Model Improved\n",
      "best loss changed : 0.007015397362348308 ---> 0.00684750531628744\n",
      "141/150 Epoch  -  Training Loss = 0.0069  -  Validation Loss = 0.0068\n",
      "Model Improved\n",
      "best loss changed : 0.00684750531628744 ---> 0.006719852867457853\n",
      "142/150 Epoch  -  Training Loss = 0.0069  -  Validation Loss = 0.0067\n",
      "Model Improved\n",
      "best loss changed : 0.006719852867457853 ---> 0.006601109172077781\n",
      "143/150 Epoch  -  Training Loss = 0.0068  -  Validation Loss = 0.0066\n",
      "Model Improved\n",
      "best loss changed : 0.006601109172077781 ---> 0.006468248355102478\n",
      "144/150 Epoch  -  Training Loss = 0.0067  -  Validation Loss = 0.0065\n",
      "Model Improved\n",
      "best loss changed : 0.006468248355102478 ---> 0.0063442662916562385\n",
      "145/150 Epoch  -  Training Loss = 0.0067  -  Validation Loss = 0.0063\n",
      "Model Improved\n",
      "best loss changed : 0.0063442662916562385 ---> 0.006228998501649813\n",
      "146/150 Epoch  -  Training Loss = 0.0067  -  Validation Loss = 0.0062\n",
      "Model Improved\n",
      "best loss changed : 0.006228998501649813 ---> 0.006113738517741483\n",
      "147/150 Epoch  -  Training Loss = 0.0064  -  Validation Loss = 0.0061\n",
      "Model Improved\n",
      "best loss changed : 0.006113738517741483 ---> 0.006027265197257886\n",
      "148/150 Epoch  -  Training Loss = 0.0065  -  Validation Loss = 0.0060\n",
      "Model Improved\n",
      "best loss changed : 0.006027265197257886 ---> 0.005986969776298383\n",
      "149/150 Epoch  -  Training Loss = 0.0063  -  Validation Loss = 0.0060\n",
      "Model Improved\n",
      "best loss changed : 0.005986969776298383 ---> 0.00588202111352685\n",
      "150/150 Epoch  -  Training Loss = 0.0062  -  Validation Loss = 0.0059\n"
     ]
    }
   ],
   "source": [
    "seq2seq = Seq2Seq(Q_vocab.words_count, hidden_size, A_vocab.words_count)\n",
    "\n",
    "train(source_data = source_data,\n",
    "      target_data = target_data,\n",
    "      model = seq2seq,\n",
    "      epochs = epochs,\n",
    "      learning_rate = learning_rate,\n",
    "      batch_size = batch_size,\n",
    "      setting_patience = 10\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oQLTP2Wmi1eB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(4504, 256)\n",
       "    (lstm): LSTM(256, 256)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(4079, 256)\n",
       "    (lstm): LSTM(256, 256)\n",
       "    (fc): Linear(in_features=256, out_features=4079, bias=True)\n",
       "    (softmax): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'checkpoint.pt'\n",
    "\n",
    "seq2seq = Seq2Seq(Q_vocab.words_count, hidden_size, A_vocab.words_count)\n",
    "seq2seq.load_state_dict(torch.load(model_path, map_location='cuda'))\n",
    "seq2seq.cuda()\n",
    "seq2seq.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'exit' to finish the chat.\n",
      " ------------------------------ \n",
      "\n",
      "> What is the biggest building?\n",
      "< fort hill \n",
      "\n",
      "> then, What is the second biggest building?\n",
      "< queen of \n",
      "\n",
      "> Thank you\n",
      "< skyfal \n",
      "\n",
      "> hello\n",
      "Error: Word Encountered Not In The Vocabulary.\n",
      "> haha\n",
      "Error: Word Encountered Not In The Vocabulary.\n",
      "> exit\n"
     ]
    }
   ],
   "source": [
    "print(\"Type 'exit' to finish the chat.\\n\", \"-\"*30, '\\n')\n",
    "while (True):\n",
    "    src = input(\"> \")\n",
    "    if src.strip() == \"exit\":\n",
    "        break\n",
    "    evaluate(src, Q_vocab, A_vocab, seq2seq, max_trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "(Starter Code) LSTM Bot",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
